<p>
  <span data-role="tag" data-value="5dde8cf7-b0a9-8834-49a3-a40bb6851fbb" id="idd86f7c8a-6946-1d56-bbf9-edb2415625cd" data-type="figure">Figure 3</span>&nbsp;illustrates a perspective view of a wearable&nbsp;augmented&nbsp;reality&nbsp;(&ldquo;AR&rdquo;) device&nbsp;( 
  <span data-role="tag" data-value="73eeafc8-fa87-e8f8-31f7-ef127ebc2f0f" id="idd5b99d43-3ac7-bfe4-72f1-d12f82164268" data-type="drawingObject">device 300</span>), from the perspective of a wearer of the 
  <span data-role="tag" data-value="73eeafc8-fa87-e8f8-31f7-ef127ebc2f0f" id="idc9a430f5-9bd2-6519-6125-f9ece637d5a1" data-type="drawingObject">device 300</span> (&ldquo;AR user&rdquo;). The 
  <span data-role="tag" data-value="73eeafc8-fa87-e8f8-31f7-ef127ebc2f0f" id="id38c30890-67d5-2765-7b46-b42538f5efca" data-type="drawingObject">device 300</span>&nbsp;is a computer device in the form of a wearable headset.&nbsp;
</p>
<p>The&nbsp;
  <span data-role="tag" data-value="73eeafc8-fa87-e8f8-31f7-ef127ebc2f0f" id="id764addee-a92e-ea84-6ed5-771b63708e0d" data-type="drawingObject">device 300</span> comprises a 
  <span data-role="tag" data-value="b5bf4435-35e0-7c3c-f20e-1875f0cb9376" id="idf66d08fb-b517-f411-6703-afe04adaf5b8" data-type="drawingObject">headpiece 302</span>, which is a headband, arranged to be worn on the wearer&#39;s head. The 
  <span data-role="tag" data-value="b5bf4435-35e0-7c3c-f20e-1875f0cb9376" id="idf40abf1a-a2cf-f933-0898-b6669a5ee7f3" data-type="drawingObject">headpiece 302</span>&nbsp;has a 
  <span data-role="tag" data-value="e8d9aeab-af7d-bd55-3aaf-9ac2b0d545f5" id="id8ac5ccd8-e1a1-a1c0-232f-02be23b5ae9b" data-type="drawingObject">central portion 304</span>&nbsp;intended to fit over the nose bridge of a wearer, and has an inner curvature intended to wrap around the wearer&#39;s head above their ears.
</p>
<p>The 
  <span data-role="tag" data-value="b5bf4435-35e0-7c3c-f20e-1875f0cb9376" id="idbe8b5cf3-0809-7913-ad94-3547fd197b78" data-type="drawingObject">headpiece 302</span>&nbsp;supports a 
  <span data-role="tag" data-value="6e942276-f92c-5b77-916f-7062aa307d13" id="id12630237-456a-26ad-46fc-4f810a358b33" data-type="drawingObject">left&nbsp;optical component 306</span>&nbsp;and a 
  <span data-role="tag" data-value="663a2e72-fa0e-6cd5-e9f4-8dda8d018c1f" id="id54500197-b1c9-3529-4115-2383434dcda2" data-type="drawingObject">right optical component 308</span>, which are waveguides. For ease of reference herein an optical component will be considered to be either a left or right component, because in the described embodiment the components are essentially identical apart from being mirror images of each other. Therefore, all description pertaining to the left-hand component also pertains to the right-hand component. The 
  <span data-role="tag" data-value="73eeafc8-fa87-e8f8-31f7-ef127ebc2f0f" id="idba07267b-6768-98f6-3373-dd0b06b4482f" data-type="drawingObject">device 300</span>&nbsp;comprises 
  <span data-role="tag" data-value="7e0e5636-3a7e-194c-628a-d9fa21e7b128" id="idb046483c-0b24-fc4d-3cc3-b9138122fb9f" data-type="drawingObject">augmented reality device&nbsp;logic 400</span>&nbsp;that is depicted in 
  <span data-role="tag" data-value="da8026c5-18ef-e477-66c7-5b5718cdc554" id="id9e33ccef-c3db-c8c0-1717-b9707e3487d9" data-type="figure">Figure 4</span>.
</p>
<p>The 
  <span data-role="tag" data-value="7e0e5636-3a7e-194c-628a-d9fa21e7b128" id="id958453b0-aeb9-dd8e-9037-9933bc928fbc" data-type="drawingObject">augmented reality device&nbsp;logic 400</span>&nbsp;comprises a 
  <span data-role="tag" data-value="23691805-eaaf-d2d5-10f1-01848d1f9575" id="id746145c1-5dc6-1c81-e890-77a415a39222" data-type="drawingObject">graphics engine 402</span>, which may comprise a micro display and imaging optics in the form of a collimating lens (not shown). The micro display can be any type of image source, such as liquid crystal on silicon (LCOS) displays, transmissive liquid crystal displays (LCD), matrix arrays of LED&#39;s (whether organic or inorganic) and any other suitable display. The display is driven by circuitry known in the art to activate&nbsp;individual pixels of the display to generate an image. Substantially collimated light, from each pixel, falls on an exit pupil of the 
  <span data-role="tag" data-value="23691805-eaaf-d2d5-10f1-01848d1f9575" id="id1e200528-6a26-0166-8853-b1bfce34b015" data-type="drawingObject">graphics engine 402</span>. At the exit pupil, the collimated light beams are coupled into each of the 
  <span data-role="tag" data-value="6e942276-f92c-5b77-916f-7062aa307d13" id="id1ad1058f-6656-0911-e6ff-fdcbb69e14c1" data-type="drawingObject">left&nbsp;optical component 306</span>&nbsp;and the 
  <span data-role="tag" data-value="663a2e72-fa0e-6cd5-e9f4-8dda8d018c1f" id="id67f24ad0-8aa1-6f63-bf85-125b46497cb9" data-type="drawingObject">right optical component 308</span> into a respective 
  <span data-role="tag" data-value="1dfdf15e-cf9f-6a7f-0b74-2e093b437aa7" id="idef840463-d99e-6a7b-1f3f-de8b9fcb7558" data-type="drawingObject">left in-coupling zone 310</span>&nbsp;and 
  <span data-role="tag" data-value="8fb3ebaa-3466-b67b-de4c-14617b279eb2" id="id558a2a86-e6c3-da2f-ea83-8200bcd43d31" data-type="drawingObject">rightin-coupling zone 312</span>. In-coupled light is then guided, through a mechanism that involves diffraction and TIR, laterally of the optical component in a respective 
  <span data-role="tag" data-value="2cdf9d73-6eb5-ccc5-e2b2-8768718dfa70" id="id12bbf3da-745b-94ce-1210-55f6eb47e8ed" data-type="drawingObject">left intermediate zone 314</span>&nbsp;and 416, and also downward into a respective 
  <span data-role="tag" data-value="e24e6b2b-52e5-9b78-d449-16992c88bf8d" id="id4b497044-29eb-8f96-55f5-5920a4bdb1c5" data-type="drawingObject">left exit zone 318</span>&nbsp;and 
  <span data-role="tag" data-value="0ec341b2-5e65-7e4f-d94e-2203ab956aec" id="idbd15576c-ef94-7868-af56-5e34a31151fa" data-type="drawingObject">right exit zone 320</span> where it exits towards the users&#39; eye.&nbsp;
</p>
<p>The collimating lens collimates the image into a plurality of beams, which form a virtual version of the displayed image, the virtual version being a virtual image at infinity in the optics sense. The light exits as a plurality of beams, corresponding to the input beams and forming substantially the same virtual image, which the lens of the eye projects onto the retina to form a real image visible to the user. In this manner, the 
  <span data-role="tag" data-value="6e942276-f92c-5b77-916f-7062aa307d13" id="idb7b0c8d3-5e2b-107c-5f76-40432a222915" data-type="drawingObject">left&nbsp;optical component 306</span>&nbsp;and the 
  <span data-role="tag" data-value="663a2e72-fa0e-6cd5-e9f4-8dda8d018c1f" id="id06cc32ba-3319-5526-1ea0-030bda7c695e" data-type="drawingObject">right optical component 308</span> project&nbsp;the displayed image onto the wearer&#39;s eyes.&nbsp;
</p>
<p>The various optical zones can, for example, be suitably arranged diffractions gratings or holograms. Each optical component has a refractive index n which is such that total internal reflection takes place to guide the beam from the light engine along the respective intermediate expansion zone, and down towards respective the exit zone.</p>
<p>Each optical component is substantially transparent, whereby the wearer can see through it to view a real-world environment in which they are located simultaneously with the projected image, thereby providing an&nbsp;augmented&nbsp;reality&nbsp;experience.</p>
<p>To provide a stereoscopic image, i.e. that is perceived as having 3D structure by the user, slightly different versions of a 2D image can be projected onto each eyefor &nbsp;example from multiple&nbsp;
  <span data-role="tag" data-value="23691805-eaaf-d2d5-10f1-01848d1f9575" id="id9b533bd9-6a7a-90ec-f086-e8bf99172c56" data-type="drawingObject">graphics engine 402</span>&nbsp; (i.e. two micro displays), or from the same light engine (i.e. one micro display) using suitable optics to split the light output from the single display.
</p>
<p>The 
  <span data-role="tag" data-value="73eeafc8-fa87-e8f8-31f7-ef127ebc2f0f" id="id05e060b7-d614-573b-d19d-1a406dfbdb4d" data-type="drawingObject">device 300</span>&nbsp;is just one exemplary configuration. For instance, where two light-engines are used, these may instead be at separate locations to the right and left of the device (near the wearer&#39;s ears). Moreover, whilst in this example, the input beams that form the virtual image are generated by collimating light from the display, an alternative light engine based on so-called scanning can replicate this effect with a single beam, the orientation of which is fast modulated whilst simultaneously modulating its intensity and/or colour. A virtual image can be simulated in this manner that is equivalent to a virtual image that would be created by collimating light of a (real) image on a display with collimating optics. Alternatively, a similar AR experience can be provided by embedding substantially transparent pixels in a glass or polymer plate in front of the wearer&#39;s eyes, having a similar configuration to the 
  <span data-role="tag" data-value="6e942276-f92c-5b77-916f-7062aa307d13" id="idfbb6f7b0-dd1b-61c4-27c9-9428ac1e7685" data-type="drawingObject">left&nbsp;optical component 306</span>&nbsp;and 
  <span data-role="tag" data-value="663a2e72-fa0e-6cd5-e9f4-8dda8d018c1f" id="idc8e94190-180c-303e-b9a4-fb783ad55670" data-type="drawingObject">right optical component 308</span>&nbsp;though without the need for the zone structures.
</p>
<p>Other 
  <span data-role="tag" data-value="b5bf4435-35e0-7c3c-f20e-1875f0cb9376" id="idf8ab44e2-00de-9301-7489-0e887011123f" data-type="drawingObject">headpiece 302</span>&nbsp;embodiments are also within the scope of the subject matter. For instance, the display optics can equally be attached to the users head using a frame (in the manner of conventional spectacles), helmet or other fit&nbsp;
  <span data-role="tag" data-value="ff87214a-69f9-22e7-1084-5e8cca3451e0" id="idfe7f22e4-8ad3-fdcf-efec-f552238d1e03" data-type="term">system</span>. The purpose of the fit&nbsp;
  <span data-role="tag" data-value="ff87214a-69f9-22e7-1084-5e8cca3451e0" id="idae2dc7f8-485a-0ba9-c054-4042d9a65523" data-type="term">system</span>&nbsp;is to support the display and provide stability to the display and other head borne&nbsp;systems&nbsp;such as tracking&nbsp;systems&nbsp;and cameras. The fit&nbsp;
  <span data-role="tag" data-value="ff87214a-69f9-22e7-1084-5e8cca3451e0" id="id57336572-5ed4-5e71-2705-373e13c3b4fa" data-type="term">system</span>&nbsp;can be designed to meet user population in anthropometric range and head morphology and provide comfortable support of the display&nbsp;
  <span data-role="tag" data-value="ff87214a-69f9-22e7-1084-5e8cca3451e0" id="id46dd9ec7-85db-59e8-dd73-f93cfdecb21f" data-type="term">system</span>.
</p>
<p>The 
  <span data-role="tag" data-value="73eeafc8-fa87-e8f8-31f7-ef127ebc2f0f" id="id20f5fc72-4f46-5588-a115-71a37341b963" data-type="drawingObject">device 300</span>&nbsp;also comprises one or more 
  <span data-role="tag" data-value="756601ab-e37f-96f4-01a4-9e8a9741add6" id="ide75def21-12bb-8152-6536-779b6c13e4d7" data-type="drawingObject">camera 404</span>&nbsp;&mdash; for example 
  <span data-role="tag" data-value="5b9fa0b9-cc16-f32f-6564-a15fe0133a8d" id="id6777ad80-4363-e679-3895-11a30faa80d0" data-type="drawingObject">left stereo camera 322</span>&nbsp;and 
  <span data-role="tag" data-value="eba5868b-d1c7-4ad8-a170-48ca6a212b35" id="id4099dc9e-baed-38fb-f015-d362fe40183c" data-type="drawingObject">right stereo camera 324</span> mounted on the 
  <span data-role="tag" data-value="b5bf4435-35e0-7c3c-f20e-1875f0cb9376" id="idcc2b6d10-e213-bc77-cec1-b8635fc31809" data-type="drawingObject">headpiece 302</span> and configured to capture an approximate view (&ldquo;field of view&rdquo;) from the user&#39;s left and right eyes respectfully in this example. The cameras are located towards either side of the user&#39;s head on the 
  <span data-role="tag" data-value="b5bf4435-35e0-7c3c-f20e-1875f0cb9376" id="idf3ec3eb4-8844-fc22-3853-b2cb2cec5552" data-type="drawingObject">headpiece 302</span>, and thus capture images of the scene forward of the device form slightly different perspectives. In combination, the stereo 
  <span data-role="tag" data-value="1b0f7f5a-4f97-2904-3cde-dc249f14c78c" id="idca4424bd-4785-47a5-e3e1-8ee6f5e2ee2d" data-type="term">camera</span>&#39;s capture a stereoscopic moving image of the real-wold environment as the device moves through it. A stereoscopic moving image means two moving images showing slightly different perspectives of the same scene, each formed of a temporal sequence of frames to be played out in quick succession to replicate movement. When combined, the two images give the impression of moving 3D structure.
</p>
<p>A 
  <span data-role="tag" data-value="6c60c03a-7839-2d19-3690-6250b84e3fed" id="ida6d37810-d49b-f840-1e35-adfac85b9b4c" data-type="drawingObject">left microphone 326</span> and a 
  <span data-role="tag" data-value="010a29c1-3f67-752b-6a07-eb5bbc71349a" id="id56f8cb59-f948-92e8-b7b4-414a7696f2be" data-type="drawingObject">right microphone 328</span>&nbsp;are located at the front of the headpiece (from the perspective of the wearer), and left and right channel speakers, earpiece or other audio output transducers are to the left and right of the 
  <span data-role="tag" data-value="b5bf4435-35e0-7c3c-f20e-1875f0cb9376" id="id11f4d8b2-0de2-8207-b768-37b8414875e7" data-type="drawingObject">headpiece 302</span>. These are in the form of a pair of bone conduction audio transducers functioning as a 
  <span data-role="tag" data-value="9a0aad60-80d2-ed31-fab9-4d3ae6dfda27" id="idba473a02-e233-be12-9d1f-20362fb148a9" data-type="drawingObject">left speaker 330</span>&nbsp;and 
  <span data-role="tag" data-value="b0c728cd-1737-5dec-1d90-5c3a6193b35f" id="id2e273f71-6383-3d25-3971-eb87b9c39843" data-type="drawingObject">right speaker 332</span>&nbsp;audio channel output.
</p>